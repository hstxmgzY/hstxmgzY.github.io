# 概率

## 第一章

### 条件概率

> 定义
>
> + $\Omega$ 样本空间 $A,B$两个事件
> + $P(B)>0$ ，在 $B$ 已经发生的条件下 $A$ 发生的概率

$$
P(A|B) = \frac{P(AB)}{P(B)}
$$

### 乘法公式

$$
P(AB) = P(A|B)P(B)
$$

$$
P(AB) = P(B|A)P(A)
$$

### 全概率公式

> 定理
>
> + $A_1,A_2, ..., A_n$ 是 $E$ 的**完备事件组**（互不相容且并为 $\Omega$ ）
> + $P(A_i)>0$

$$
P(B) = \sum^{n}_{i=1}P(A_i)P(B|A_i)
$$

![image-20240331122329556](%E6%A6%82%E7%8E%87%E8%AE%BA.assets/image-20240331122329556.png)

> 什么时候用？
>
> + 已经知道全集（样本空间）可以分成n个子集（互不相容），而且划分的概率都是知道的（比如情况1是三分之一。。。），要求的东西的概率在这些子集之间。
> + 举个例子，有10台冰箱，有3台是次品，已经卖了两台，问再取一台是正品的概率。那这道题就可以考虑前两台中的情况（1正1次，2次，2正）顺序不重要——这些就是A，而B则是第三台是正品。
>
> $$
> \begin{aligned}
>     P(B) &= \sum^{n}_{i=1}P(A_i)P(B|A_i) \\
>     &= P(A_1)P(B|A_1) + P(A_2)P(B|A_2)+P(A_3)p(B|A_3) \\
>     &= \frac{C_{7}^{1}C_3^1}{C_{10}^2} \times \frac{6}{8} + \frac{C_3^2}{C_{10}^2} \times \frac{7}{8}+ \frac{C_{7}^{2}}{C_{10}^2} \times \frac{5}{8}
> \end{aligned}
> $$
>
> 



### 贝叶斯公式(果->因)

> 定理
>
> + $A_1,A_2, ..., A_n$ 是 $E$ 的**完备事件组**（互不相容且并为 $\Omega$ ）
> + $P(B)>0$ ，$P(A_i)>0$

$$
P(A_k|B) = \frac{P(A_kB)}{P(B)}=\frac{P(A_k)P(B|A_k)}{\sum^{n}_{i=1}P(A_i)P(B|A_i)}
$$

> 要让分子分母变得的差不多
>
> + 可以观察到，分子用乘法公式算得，分母用全概率公式算得
>
> 什么时候用？
>
> + 已经知道结果，要求原因。
>   + 比如说 有四个厂子生产东西，有正品也有次品，我们已经知道了不合格的产品的P和四个厂子的产率，现在需要问你这些不合格的产品中，是第四个厂子生产出来的概率？ 

### 事件的独立性

> 定义：
>
> + A的概率不受B发生与否的影响
>
> $$
> P(A|B) = P(A)
> $$

> 定理：
>
> + $P(A)>0,P(B)>0$
>

> $$
> A,B 独立 \leftrightarrow P(AB)=P(A)P(B)
> $$

> + 若$A,B$ 独立，则 $A$ 与 $\overline{B}$ ，$\overline{A}$ 与 $B$ ， $\overline{A}$ 与 $\overline{B}$ 独立
> + $P(A)=0$ 或 $P(A)=1$ ，A与任何事件独立 

### 频率

$$
f_n=\frac{n_A}{n}
$$

+ 其中，$n_A$ 指的是随机事件A在试验中发生的次数，$n$指的是试验总次数

#### 频率的性质

1. $P(A) = 1-P(\overline{A})$
2. 当 $A\supset B$ 时，$P(A) \ge P(B)$
3. $P(A \cup B)=P(A) + P(B)-P(AB)$
	1. $P(A \cup B \cup C) = P(A) + P(B) - P(AB) - P(BC) - P(AC) + P(ABC)$
	2. 其实就是偶数减，奇数加。



## 第二章

### 随机变量

在概率论和统计学中，随机变量是对**随机现象结果的数学描述**。换句话说，它是一个函数，将样本空间中的每个可能的结果映射到一个实数上。随机变量可以是离散的，也可以是连续的。

1. **离散随机变量**：取有限个或可数无限个值的随机变量。例如，抛硬币的结果（正面或反面）、掷骰子的结果（1、2、3、4、5 或 6）、抽取一副扑克牌中一张牌的花色等。

2. **连续随机变量**：取值范围是一个或多个连续的实数区间的随机变量。例如，一个人的身高、一辆车的速度、一次测量的温度等。

当谈及随机变量时，通常用符号来表示。假设我们有一个样本空间 \(S\)，其中包含所有可能的结果。一个随机变量 \(X\) 是一个函数，将样本空间中的每个结果映射到实数上。通常用 \(X\) 来表示随机变量，其可能的取值用 \(x\) 表示。

+ 对于**离散随机变量**，我们可以表示为：

\[ X : S \rightarrow \mathbb{R} \]

其中，\(X\) 将样本空间中的每个结果 \(s \in S\) 映射到一个实数上，即 \(X(s) = x\)。

+ 对于**连续随机变量**，我们可以表示为：

\[ X : S \rightarrow \mathbb{R} \]

同样，\(X\) 将样本空间中的每个结果 \(s \in S\) 映射到一个实数上。



在实际问题中，我们经常关注随机变量的分布和性质。因此，我们可以使用**概率分布函数**来描述随机变量的可能取值及其对应的概率。不同的随机变量有不同的累积分布函数，常见的随机变量包括离散型随机变量和连续型随机变量，它们对应的**累积分布函数**分别为概率质量函数的**累积**和概率密度函数的**积分**。

对于离散随机变量 \(X\)，其 PMF （概率质量函数）可以表示为：

\[ P(X = x) \]

表示随机变量 \(X\) 取值为 \(x\) 的概率。

对于连续随机变量 \(X\)，其 PDF （概率密度函数）可以表示为：

\[ f_X(x) \]

表示随机变量 \(X\) 取值在 \(x\) 附近的概率密度。

#### 分布函数

概率分布函数是描述随机变量在给定点处取值的概率的函数。分布函数 \(F_X(x)\) 定义为随机变量 \(X\) 小于或等于 \(x\) 的概率：

\[ F_X(x) = P(X \leq x) \]

累积分布函数具有以下性质：

1. 对于任意的实数 \(x\)，概率分布函数的值都在区间 \([0, 1]\) 内：\( 0 \leq F_X(x) \leq 1 \)。

2. 随着 \(x\) 的增加，概率分布函数**单调不减**：\( if\quad x_1<x_2, then\quad F(x_1)\le F(x_2) \)  。

3. 在 \(x\) 趋于负无穷时，概率分布函数趋近于 0；在 \(x\) 趋于正无穷时，概率分布函数趋近于 1。**(用于求参数)**

4. 概率分布函数是**右连续**的，即对于任意的 \(x\)，\(F_X(x)\) 在 \(x\) 处连续。（离散型 右连续，连续性 连续）

> 补充：连续 左连续 右连续
>
> 在数学中，连续性是描述函数在某个点处的性质的概念。右连续、左连续和连续是指函数在该点处的取值与函数在该点的左侧和右侧的极限之间的关系。
>
> 1. **右连续**（Right-continuous）：如果函数在某个点 \(x\) 处的右极限等于函数在该点的值，那么该函数在点 \(x\) 处是右连续的。具体来说，如果对于函数 \(f(x)\) ，当 \(x \to c^+\) 时，有 \(\lim_{x \to c^+} f(x) = f(c)\)，则函数 \(f(x)\) 在点 \(x = c\) 处是右连续的。
>
> 2. **左连续**（Left-continuous）：如果函数在某个点 \(x\) 处的左极限等于函数在该点的值，那么该函数在点 \(x\) 处是左连续的。具体来说，如果对于函数 \(f(x)\)，当 \(x \to c^-\) 时，有 \(\lim_{x \to c^-} f(x) = f(c)\)，则函数 \(f(x)\) 在点 \(x = c\) 处是左连续的。
>
> 3. **连续**（Continuous）：如果函数在某个点 \(x\) 处既是右连续的又是左连续的，且函数在该点的值等于其左极限和右极限，那么该函数在点 \(x\) 处是连续的。换句话说，如果函数 \(f(x)\) 在点 \(x = c\) 处既是右连续的又是左连续的，并且满足 \(\lim_{x \to c^+} f(x) = f(c)=\lim_{x \to c^-} f(x) = f(c)=\lim_{x \to c} f(x) = f(c)\)，则函数 \(f(x)\) 在点 \(x = c\) 处是连续的。
>
> 在实数轴上，右连续、左连续和连续的概念帮助我们理解函数在某个点处的性质，特别是在讨论极限和函数的连续性时非常有用。

概率分布函数可以用来计算随机变量 \(X\) 在某个区间内的概率，具体为：

\[ P(a < X \leq b) = F_X(b) - F_X(a) \]

其中 \(a\) 和 \(b\) 是任意的实数，表示区间的上下界。



### 离散型随机变量及其概率分布

#### 定义**（离散）**

+ 取值可数的随机变量为**离散量**
+ 离散型随机变量是指其可能取值为**有限个**或者**可数无限个**的随机变量。离散型随机变量的概率分布通常由概率质量函数（Probability Mass Function，PMF）来描述。

概率质量函数 \(P(X = x)\) 给出了随机变量 \(X\) 取特定值 \(x\) 的概率。它满足以下两个条件：

1. 对于所有可能的 \(x\) 值，概率质量函数的值都是非负的：\(P(X = x) \geq 0\)。
2. 所有可能的 \(x\) 值的概率之和等于 1：\(\sum_{\text{all } x} P(X = x) = 1\)。

常见的离散型随机变量及其概率分布包括：

#### **伯努利分布（Bernoulli Distribution）/ 0-1分布**

- 描述了**只有两种可能结果**的随机试验，如抛一次硬币的结果（正面或反面）。
- 概率质量函数：\(P(X = k) = p^k (1-p)^{1-k}\)，其中 \(k \in \{0, 1\}\)，\(p\) 表示成功的概率。

#### **二项分布（Binomial Distribution）**$X\sim B(n,p)$

- 描述了进行多次独立的伯努利试验（n重伯努利试验），并统计成功次数的分布。
- 概率质量函数：\(P(X = k) = \binom{n}{k} p^k (1-p)^{n-k}\)，其中 \(k\) 表示成功的次数，\(n\) 表示试验次数，\(p\) 表示单次试验中的成功概率。

#### **泊松分布（Poisson Distribution）$X\sim \pi(\lambda)$**

- 描述了在一定时间或空间内随机事件发生的次数的分布。
- 概率质量函数：\(P(X = k) = \frac{\lambda^k }{k!} e^{-\lambda}\)，其中 \(k\) 表示事件发生的次数，\(\lambda\) 表示单位时间或单位空间内事件发生的平均次数。
- 泊松分布通常用于描述低概率事件在一段时间或空间内发生的次数，比如电话呼叫数量、交通事故数量、客户到达数量等。

  下面通过一个例子来解释 \(\lambda\) 的含义：

  假设某个停车场在一小时内平均发生车辆进入的次数为 5 辆。我们可以用泊松分布来描述这种现象。在这个例子中，每小时进入的车辆数就是随机变量 \(X\)，而泊松分布的参数 \(\lambda\) 就是 5，即 \(\lambda = 5\)。

  现在，我们来计算在一小时内进入的车辆数符合泊松分布的概率。例如，我们想知道在这个停车场中，一小时内进入的车辆数为 3 辆的概率是多少。我们可以使用泊松分布的概率质量函数：

  

\[ P(X = 3) = \frac{5^3 e^{-5}}{3!} \approx 0.14037 \]

#### 二项分布用泊松分布近似

当二项分布中的试验次数 \(n\) 很大，成功概率 \(p\) 很小，但成功次数 \(np\) 保持一定的大小时，可以使用泊松分布来近似描述二项分布。

具体来说，当 \(n\) 很大，\(p\) 很小，且 (np) 适中时，二项分布 \(B(n, p)\) 可以近似为参数 \(\lambda = np\) 的泊松分布 \(P(\lambda)\)。这是因为在这种情况下，二项分布的概率质量函数中的各项变得非常接近，而且随着 \(n\) 的增大和 \(p\) 的减小，二项分布的形状越来越类似于泊松分布。

泊松分布的概率质量函数为：

\[ P(X = k) = \frac{\lambda^k e^{-\lambda}}{k!} \]

其中，\(k\) 表示事件发生的次数，\(\lambda\) 表示事件在单位时间或单位空间内的平均发生率。

在使用泊松分布来近似二项分布时，我们有以下关系：

\[ \lambda = np \]

这意味着泊松分布的参数 \(\lambda\) 可以由二项分布的参数 \(n\) 和 \(p\) 来确定。在二项分布 \(B(n, p)\) 中，如果 \(n\) 很大，\(p\) 很小时，\(np = \lambda\) 会保持相对稳定的值。

当 \(n\) 很大且 \(p\) 很小时，二项分布的概率质量函数中的各项变得非常接近的原因如下：

1. **期望值近似相等**：在二项分布 \(B(n, p)\) 中，其期望值为 \(np\)。因此，当 \(n\) 很大，\(p\) 很小时，虽然每次试验成功的概率很小，但由于试验次数 \(n\) 很大，\(np\) 依然保持一定的大小。这意味着二项分布的期望值仍然比较稳定。而泊松分布的参数 \(\lambda\) 也是由 \(np\) 决定的，因此在这种情况下，二项分布的期望值与泊松分布的参数相近。

2. **方差逐渐变小**：二项分布的方差为 \(np(1-p)\)，当 \(n\) 很大，\(p\) 很小时，\(np(1-p)\) 也会逐渐变小。这意味着二项分布在这种情况下的波动性减小，使得其形状越来越接近于泊松分布，而泊松分布具有较小的方差。

3. **大数定律**：当 \(n\) 很大时，根据大数定律，独立重复试验的平均值会趋于其期望值。即使每次试验成功的概率很小，但由于试验次数 \(n\) 很大，成功的次数 \(np\) 的分布也会趋近于其期望值，这就导致了二项分布的形状逐渐接近于泊松分布。

综上所述，当 \(n\) 很大且 \(p\) 很小时，二项分布的概率质量函数中的各项变得非常接近，这是因为在这种情况下，二项分布的期望值稳定，方差减小，同时符合大数定律，使得其分布形状越来越类似于泊松分布。

#### **几何分布（Geometric Distribution）**$X\sim G(p)$

- 描述了在一系列独立的伯努利试验中，首次出现成功所需的试验次数。
- 概率质量函数：\(P(X = k) = (1-p)^{k-1} p\)，其中 \(k \geq 1\)，\(p\) 表示成功的概率。

---

### 连续型随机变量及其概率密度

#### 定义

+ 非负可积 $f(x)$， $f(x)\ge 0$， $a\le b$ ，使得对任意实数 $a, b$ 都有$P\{a<x\le b\}=\int_a^b f(x)dx$ ，就称 $x$ 为**连续型随机变量**，$f(x)$ 为 $x$ 的概率分布密度函数，简称概率密度。

连续型随机变量的概率密度函数 \(f_X(x)\) 满足以下两个条件：

1. 对于所有可能的 \(x\) 值，概率密度函数的值都是非负的：\(f_X(x) \geq 0\)。
2. 在整个实数轴上，概率密度函数的积分等于 1：\(\int_{-\infty}^{\infty} f_X(x) \, dx = 1\)。

因为**连续型随机变量在单个点上的概率为零**，我们通常使用概率密度函数来描述随机变量在**某个区间**内的概率。具体来说，概率密度函数 \(f_X(x)\) 在区间 \((a, b)\) 内的概率可以通过对概率密度函数在该区间上的积分来计算：

\[ P(a < X < b) = \int_{a}^{b} f_X(x) \, dx \]

这个积分表示了随机变量 \(X\) 在区间 \((a, b)\) 内取值的概率。



常见的连续型随机变量及其概率密度函数包括：

#### **均匀分布（Uniform Distribution）** \(X \sim U(a, b)\)

- 在某个区间 \((a, b)\) 上概率密度函数为常数，表示该区间内任何一个子区间内取值的概率相同。

均匀分布（Uniform Distribution）是一种简单的概率分布，其中随机变量在给定的区间内取值的概率是相等的。具体地说，如果随机变量 \(X\) 在区间 \([a, b]\) 内服从均匀分布，我们记作 \(X \sim U(a, b)\)。

##### 概率密度函数

均匀分布的概率密度函数 \(f_X(x)\) 定义在区间 \([a, b]\) 上，并且在该区间内的取值是常数。因为在整个区间内的概率密度应该等于 1，我们可以将均匀分布的概率密度函数表示为：

\[
f_X(x) = 
\begin{cases} 
\frac{1}{b - a}, & \text{当 } a \leq x \leq b \\
0, & \text{其他情况}
\end{cases}
\]

这里，\(a\) 和 \(b\) 是区间的下界和上界，\(b > a\)。概率密度函数 \(f_X(x)\) 在区间 \([a, b]\) 内是常数 \(\frac{1}{b - a}\)，表示该区间内的任意子区间的概率是相等的。

![img](%E6%A6%82%E7%8E%87%E8%AE%BA.assets/350px-Uniform_distribution_PDF.png)

##### 分布函数

均匀分布的累积分布函数 \(F_X(x)\) 可以通过对概率密度函数在给定点 \(x\) 之前的区间上进行积分来得到，即：

\[
F_X(x) = 
\begin{cases} 
0, & \text{当 } x < a \\
\frac{x - a}{b - a}, & \text{当 } a \leq x \leq b \\
1, & \text{当 } x > b
\end{cases}
\]

积分过程：

\[
\int^x_{-\infty}f(t)dt=\int^a_{-\infty}f(t)dt + \int^x_af(t)dt= 0 + \int^x_a \frac{1}{b-a}dt
\]

这个累积分布函数描述了随机变量 \(X\) 小于或等于 \(x\) 的概率。在区间 \([a, b]\) 内，累积分布函数的值以线性方式从 0 增加到 1，表示随机变量落在该区间内的概率随着 \(x\) 的增加而增加。

![img](%E6%A6%82%E7%8E%87%E8%AE%BA.assets/350px-Uniform_distribution_CDF.png)



##### **期望值**（Expected Value）

均匀分布在区间 \([a, b]\) 内取值是等可能的，因此其期望值（也称为均值）等于区间的中点，即：

\[ E(X) = \frac{a + b}{2} \]

##### **中值**（Median）

由于均匀分布是对称的，区间的中点也是其中值。因此，均匀分布的中值也等于区间的中点，即：

\[ \text{Median} = \frac{a + b}{2} \]

##### **方差**（Variance）

均匀分布的方差是衡量随机变量离其期望值的距离的平均值。对于均匀分布，我们可以使用方差的公式计算：

\[ \text{Var}(X) = \frac{(b - a)^2}{12} \]

##### **等可能性**

均匀分布的特点之一是，在给定区间内的任何子区间内随机变量取值的概率都是相等的。这意味着，任何区间的长度与该区间内随机变量取值的概率成正比。

例如，对于区间 \([c, d]\)，其长度为 \(d - c\)，因此其概率为

$$
P(c\le x \le d)=F(d)-F(c)=\int^d_c\frac{1}{b-a}=\frac{d-c}{b-a}
$$


其中 \(a \leq c < d \leq b\)。

只与区间$[c,d]$的长度有关，而与它的位置无关

#### **正态分布（Normal Distribution）**  $X\sim N(\mu, \sigma^2)$

![Probability density function for the Normal distribtion](%E6%A6%82%E7%8E%87%E8%AE%BA.assets/325px-Normal_Distribution_PDF.svg.png)

##### **定义**

正态分布的概率密度函数是一个钟形曲线，由两个参数完全描述：均值 \(\mu\) 和标准差 \(\sigma\)。其概率密度函数 \(f_X(x)\) 表示为：

\[ f_X(x) = \frac{1}{ \sqrt{2\pi} \sigma} \exp\left(-\frac{(x - \mu)^2}{2\sigma^2}\right) \]

其中，\(x\) 是随机变量的取值，$-\infty < x<\infty$ ，\(\mu\) 是分布的均值，\(\sigma\) 是分布的标准差。

##### **分布函数**：

正态分布的累积分布函数（CDF）表示为 \(F_X(x)\)，它描述了随机变量 \(X\) 小于或等于 \(x\) 的概率。正态分布的累积分布函数没有解析表达式，通常使用数值计算或查找表来计算。

##### **期望值和方差**：

+ 正态分布的期望值（均值）等于分布的均值参数 \(\mu\)，即 \(E(X) = \mu\)。

+ 方差等于分布的标准差参数 \(\sigma\) 的平方，即 \(\text{Var}(X) = \sigma^2\)。

##### **特性**：

- 正态分布是对称的，关于其均值 \(\mu\) 对称。
- 在 \(x = \mu\) 处具有峰值，峰值的高度为 \(\frac{1}{\sigma \sqrt{2\pi}}\)。
- 正态分布的曲线在 \(x = \mu\) 处拐点，曲线向两侧下降。
- 标准正态分布是均值为 0，标准差为 1 的正态分布，称为 \(N(0, 1)\) 分布。

正态分布在许多领域中都有着广泛的应用，特别是在统计学和自然科学中。它的重要性在于中心极限定理，该定理指出，大量独立同分布的随机变量之和在趋近于无穷大时，近似服从正态分布。这使得正态分布成为许多统计推断方法的基础，例如假设检验、置信区间估计等。

##### 标准正态分布

标准正态分布是一种特殊的正态分布，具有均值为 0，标准差为 1 的特征。它的概率密度函数是正态分布概率密度函数的特例。

+ **概率密度函数**：
  标准正态分布的概率密度函数 \(f_Z(z)\) 定义为：

\[ f_Z(z) = \frac{1}{\sqrt{2\pi}} \exp\left(-\frac{z^2}{2}\right) \]

其中，\(z\) 是随机变量的取值，概率密度函数描述了随机变量取某个值的概率密度。

+ **分布函数**：
  标准正态分布的累积分布函数 \(F_Z(z)\) 表示随机变量 \(Z\) 小于或等于 \(z\) 的概率。标准正态分布的累积分布函数通常用符号 \(\Phi(z)\) 表示：

\[ \Phi(z) = \int_{-\infty}^{z} \frac{1}{\sqrt{2\pi}} \exp\left(-\frac{t^2}{2}\right) \, dt \]

标准正态分布的累积分布函数通常通过查找标准正态分布表或使用计算机软件进行计算。

+ **性质**：

	- 标准正态分布是对称的，其概率密度函数关于 \(z = 0\) 对称。

	- 在 \(z = 0\) 处具有峰值，峰值的高度为 \(\frac{1}{\sqrt{2\pi}}\)。

	- 标准正态分布的曲线在 \(z = 0\) 处拐点，曲线向两侧下降。

#### **指数分布（Exponential Distribution）**

- 描述了独立随机事件发生的时间间隔的概率分布，具有单峰右偏的形状。
- 指数分布可以用来建模**平均发生率恒定、连续、独立**的事件发生的间隔，比如旅客进入机场的时间间隔、电话打进客服中心的时间间隔、机器的寿命等。

指数分布（Exponential Distribution）是描述独立随机事件发生时间间隔的概率分布。它常用于描述连续时间下**等待第一个事件发生**的时间，或者是连续时间下两个事件之间的时间间隔。指数分布是一个重要的连续概率分布，具有单峰右偏的形状。

##### 概率密度函数

+ 如果随机变量 \(X\) 的概率密度函数 \(f_X(x)\) 在 \(x\) 处为 \(x \geq 0\) 的指数函数形式，则称随机变量 \(X\) 服从参数为 \(\lambda > 0\) 的指数分布，记作 \(X \sim \text{Exp}(\lambda)\)，其概率密度函数为：

\[ f_X(x) = 
\begin{cases} 
\lambda e^{-\lambda x}, & \text{当 } x \geq 0 \\
0, & \text{其他情况}
\end{cases}
\]

其中，\(\lambda > 0\) 是指数分布的参数，称为速率参数，表示单位时间内事件发生的平均次数。

指数分布的概率密度函数具有以下性质：

1. 对于所有 \(x \geq 0\)，概率密度函数的值都是非负的：\(f_X(x) \geq 0\)。
2. 在整个实数轴上，概率密度函数的积分等于 1：\(\int_{0}^{\infty} \lambda e^{-\lambda x} \, dx = 1\)。

![机率密度函数](%E6%A6%82%E7%8E%87%E8%AE%BA.assets/325px-Exponential_distribution_pdf.png)

##### 分布函数

指数分布的累积分布函数 \(F_X(x)\) 定义为随机变量 \(X\) 小于或等于 \(x\) 的概率：

\[ F_X(x) = P(X \leq x) = \int_{0}^{x} \lambda e^{-\lambda t} \, dt \]

将概率密度函数积分得到的累积分布函数为：

\[ F_X(x) = 
\begin{cases} 
1 - e^{-\lambda x}, & \text{当 } x \geq 0 \\
0, & \text{当 } x < 0
\end{cases}
\]

指数分布的累积分布函数具有以下性质：

1. 当 \(x \geq 0\) 时，累积分布函数 \(F_X(x)\) 的值在区间 \((0, 1)\) 内，且随着 \(x\) 的增加而单调递增。
2. 当 \(x < 0\) 时，累积分布函数的值为 0。

![累积分配函数](%E6%A6%82%E7%8E%87%E8%AE%BA.assets/325px-Exponential_distribution_cdf.png)

##### **期望值**（Expected Value）

指数分布的期望值（也称为均值）等于其参数的倒数，即：

\[ E(X) = \frac{1}{\lambda} \]

这意味着，事件发生的平均时间间隔为参数的倒数。

##### **方差**（Variance）

指数分布的方差等于参数的倒数的平方，即：

\[ \text{Var}(X) = \frac{1}{\lambda^2} \]

方差描述了随机变量离其期望值的平均距离，因此指数分布的方差可以理解为事件发生时间间隔的波动程度。

##### **无记忆性**（Memoryless Property）：

指数分布具有无记忆性，这意味着在给定事件尚未发生的情况下，已经等待了一段时间，那么**剩余的等待时间与之前等待的时间无关**。

具体来说，如果 \(X\) 服从指数分布 \(X \sim \text{Exp}(\lambda)\)，那么对于任意 \(s, t > 0\)，有：

\[ P(X > s + t | X > s) = P(X > t) \]

这个性质表示，已经等待了一段时间 \(s\) 之后，再等待一段时间 \(t\) 直到事件发生的概率，与开始等待的时间点无关。这种无记忆性的性质在实际应用中具有重要意义，例如在可靠性工程中，用于描述设备故障发生的时间间隔。



## 参考

+ 维基百科
  + [指数分布](https://zh.wikipedia.org/wiki/%E6%8C%87%E6%95%B0%E5%88%86%E5%B8%83)
  + [正态分布](https://zh.wikipedia.org/wiki/%E6%AD%A3%E6%80%81%E5%88%86%E5%B8%83)
+ CHATGPT-3.5